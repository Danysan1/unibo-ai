# 7. Regularization

## Model capacity

As we said, the **model capacity** is an indication of **how complex/flexible** the functions that can be learned by the model are.

Increasing the model capacity we are able to fit the moedl better and this is benefitial because it brings down the validation error, until we start to fit also noise and/or urrelevenat features that do not apply well to unseen data (overfitting).

![](assets/markdown-img-paste-2021110514212995.png)

Since the model capacity is a very general indicator, we will focus on single hyperparameters: network width and depth, input resolution, admissible range for values of parameters, training time.

To visualize what underfitting and overffining are, suppose we fit _N_ data points, generated by a noisy quadratic equation_y_ = (_ax_<sub>0</sub><sup>2</sup> + _bx_<sub>0</sub><sup>2</sup> + _c_ ) + _&epsilon;_ with different models, which are polynomials of segree _K_ of the form ![](assets/markdown-img-paste-20211105142814314.png).

![](assets/markdown-img-paste-20211105142911758.png)

## Bias and variance

The error can be divided in
 - **irreducible error**: distance between the best possible models and the perfect model;
 - **bias**: the distance between the average performance of trained models and one (the closest) of the best possible models;
 - **variance**: the distance between my model and the average performance of trained models.

The previous graph can be now improoved taking in account this division:

![](assets/markdown-img-paste-20211105144938225.png)

We usually do not have _n_ training datasets, but only one validation and one training dataset, so we approximate bias with training error and variance with the difference between training and validation (or test) error.

To get the optimal model is unfeasible to try all possible combination, because is too expensive, so in practice usually you leverage high capacity models to reach low bias and then try to reduce their variance.

This second step of reducing variance usually requires more data, but if ther are not available it's possible to rely on **regularization**.

## Regularization

Regularization is any modification we make to a learning algorithm that is intended to reduce its generalization (test) error, but **not** its training error.

Now we will review specific techniques.

### Parameter norm penalties

When using parameter norm penalties, we add a term to the loss, called **regularization loss**, which guides training to prefer simpler models.

![](assets/markdown-img-paste-2021110515242956.png)

Where _&lambda;_ is a new hyperparameter. Usually _L<sup>reg</sup>_ (_&Theta;_ ) is **_l<sub>2</sub>_** or _l<sub>1</sub>_ norm.

_l<sub>2</sub>_ regularization is also called **weight decay** beacuse every gradient descent step drives weights toward the origin (makes them decay) before applying the same update used when regularization is not present.

### Early stopping

Training time is an hyperparameter controlling the effective capacity of the model. By using, at inference time, the best performing model on the validation set, we are effectively selecting the best value for this hyperparameter.

### Label smoothing

Cross-entropy loss has the one-hot encoding of the true label as target. Yet, it can not reach it: to have loss equal to 0, softmax of the correct label should be 1, hence scores should tend to infinite.

Label smoothing assumes that labels are not perfect and smooths them.

![](assets/markdown-img-paste-20211105153915370.png)

### Dropout

In each forward pass, **randomly set some activations to zero**. The probability of dropping is an hyperparameter _p_, usually between 0.5 and 0.2.

The idea of dropout was inspired to Hinton by his bank:

>I went to my bank. The tellers kept changing and I asked
one of them why. He said he didnâ€™t know but they got
moved around a lot. I figured it must be because it would
require cooperation between employees to successfully
defraud the bank. This made me realize that randomly
removing a different subset of neurons on each example
would prevent conspiracies and thus reduce overfitting

## Regularization: a general template

A general template for regularization is to **add randomness at training time** and **average it out at test time**, like we have seen with [dropout](#dropout) and Batch Norm.

### Stochastic depth

It's a concept similar to dropout, but for full ResNet blocks: at **training time** we **shrink depth** dropping with probability 1 - _p<sub>l</sub>_ the convolutional path of a ResNet block, i.e. keep active only the residual identity path.

The survival probability decreases with depth following the formula ![](assets/markdown-img-paste-20211108113031804.png)

At **test time**, instead, we use the **unmodified network**.

### Data augmentation

The concept is to increase the number of samples generating new data by applying to input images any transofrmation that maintains the label valid.

It is very effective, because it not only adds stochasticity like the other methods, but it also increase the number of data which results in **reducing variance**.

Common transformations are rotation and flipping, but they are not always feasible. For example rotation does not maintains the label valid when applied to written text (e.g. a _q_ becomes a _b_).

Another common transformation employed by ResNet, ehich inherited from VGG, is **multi-scale training** that consists, at **training time**, in **randomly scale** the image, **sample a random crop** of it and applying random **horizontal flip** and **[color augmentation](#color-augmentation--jittering-)** to the cropped patch.

At **test time**, instead, we rescale at fixed scales and average results.

### Color augmentation (jittering)

This technique implement at first by AlexNet and then by ResNet, consists in apply **random color change of all pixels** at training time (while doing nothing at test time).

### Cutout

Cutout consists in remove (put pixels to 0 in all the channels) a random square region of the input image with 50% probability. It forces the network to use a more diverse set of features, helping generalization

### Mixup

Mixup consists in **random blending of images** at training, **blending also the labels**. While at test time we simply pass unmodified input. This should force the network to act linearly between classes and have smoother transitions from one class decision to another. Both these effects helps generalization.

## Double Descent

TODO
