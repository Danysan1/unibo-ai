# 1. ML basics and kNN

#### Table of Contents

- [Traditional Computer Vision vs. Machine Learning](#traditional-computer-vision-vs-machine-learning)
- [Image Classification Datasets](#image-classification-datasets)
- [The kNN (k nearest neighbor) classifier](#the-knn--k-nearest-neighbor--classifier)
  * [Algorithm](#algorithm)
    + [Training](#training)
    + [Testing](#testing)
  * [Hyperparameters](#hyperparameters)
  * [Model capacity](#model-capacity)
  * [Distance](#distance)


## Traditional Computer Vision vs. Machine Learning

Traditional computer vision techniques work very well in a **controlled environment**, usually available in industrial applications, where strong assumptions on edges or on other features can be made. Otherwise, they are very brittle, and it's where machine learning techniques become useful, like in **image classification**.                      

When applying machine learning methods to image classification we have a training set _D<sup>train</sup>_ and a test set _D<sup>test</sup>_. Both contain couples _(x<sup>(i)</sup>, y<sup>(i)</sup>)_, where _x<sup>(i)</sup>_ are the features representing a real world item and _y<sup>(i)</sup>_ is the output we want for that item.

## Image Classification Datasets

One of the easiest datasets is **Modified NIST (MNIST)** which has 10 classes (handwritten digits from 0 to 9). Results on MNIST may not generalize to other datasets.

A more complex but still quite easy dataset is **CIFAR 10**. It still has only 10 classes, but they are real objects and animals. **CIFAR 100** has the same specifications as CIFAR 10, but it has 100 classes. CIFAR 10 and CIFAR 100 are both subsets of the **80 million Tiny Images dataset**, which was however removed from the internet in 2020 due to the number of biases and offensive images (even child pornography) it contained.

**ImageNet** is a huge dataset containing 14 million RGB images at full resolution with an average size of about 400&times;350 with a hierarchical structure of 22k labels. ILSVRC aka **ImageNet1k** is a subset of ImageNet containing only 1000 classes and only 1.3 million training images.

Due to the inherent ambiguity of assigning only one label to each image, performance is usually reported as **top-5 accuracy**: an image is considered correctly classified if the correct label is present in 5 classes predicted by the algorithm.


## The kNN (k nearest neighbor) classifier
kNN is a **non-parametric instance-based** algorithm which can predict complex data distributions without a real "learning", but only by "memorization". Its performances only depend on the quality of the features and of the distance. Its biggest flaw is that being a **lazy algorithm** all the computation is postponed to test time.

### Algorithm

#### Training
 1. Store all the training examples and labels.

#### Testing
 1. Compute distance in feature space between the test sample and all the training examples;
 2. Retrieve labels for the closest _k_ examples;
 3. Aggregate them to define the predicted label for the test sample.

### Hyperparameters

_k_ and the distance are hyperparameters and so they are not learned from the data but we have to manually set them. This is done because they are either too hard to be learned from data or not appropriate to learn (i.e. the best value you can compute on the training set is likely to perform poorly on the test set).

### Model capacity

By increasing _k_ we decrease the model capacity of the classifier, which can be thought of as a **measure of how flexible the functions that can be learned are**. With _k = 1_ we obtain a model that can perfectly classify any training dataset. However we are not interested in training error, but only in the **generalization (or test) error** and it cannot be estimated on training data. The only way is to see how the model performs on unseen data. For this reason, we separate some examples from the training set and use them to create the validation set. Then we test hyperparameters on the validation set and select the hyperparameters combination that performs best and we finally run the model once on the test set to evaluate generalization.

### Distance

Usually, the distance used in kNN is an _l<sub>p</sub>_ norm of the difference between features:
![image](https://user-images.githubusercontent.com/31796254/134940381-4aa9a89a-4267-40b7-a66f-2134b6dacaed.png)

and in particular either the **_l<sub>1</sub>_ norm (Manhattan or city block distance)** or the **_l<sub>2</sub>_ norm (Euclidean distance)**.

To compute the distance between images the **tensors are flattened into 1D tensors**, indeed the distance between pixels in the input space is meaningless.
