# 5. Convolutional Neural Networks

Convolution can be interpreted as matrix multiplication, if we reshape inputs and outputs. The resulting matrix is a **linear operator** which **shares parameters** across its rows, is **sparse**, naturally adapts to **varying input sizes** and is **equivariant to translations**

![image](assets/markdown-img-paste-20211011122642518.png)

Images have 3 channels, so we have to extend our definition of convolution to deal with 3-dimensional tensors. So our kernel will be of size _3 x H<sub>K</sub> x W<sub>K</sub>_.

What obtain is still a 2D convolution, but over **vector-valued functions**, and not a 3D convolution since we do not slide over channels. So the output image will have only one channel, which is called feature map or activation map.

We can repeat the process with a second kernel with different weights and so on.

![image](assets/markdown-img-paste-20211011123506744.png)

Convolutional layers can be interpreted as a constrained form of linear layers. Hence, they follow the same needing of inserting **non-linear activation functions** between them in order to meaningfully compose them.

## Receptive Fields

The input pixels affecting a hidden unit are called its **receptive field**. For instance, if we apply a _H<sub>K</sub>_ &times; _W<sub>K</sub>_ kernel size at each layer, the receptive field of an element in the _L_th activation has size  
_[1 + L(H<sub>K</sub> - 1)]_ &times; _[1 + L(W<sub>K</sub> - 1)]_.

If we want to increase the receptive field we can use **strided convolution**.
